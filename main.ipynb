{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5664c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import training\n",
    "from aspp_models import fpn as get_model\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ef9c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\DELL\\Desktop\\20credit\\EEG_eye_artifact\\video\\study05\"\n",
    "result_path=r\"C:\\Users\\DELL\\Desktop\\20credit\\EEG_eye_artifact\\results\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "for i in range(1,6):\n",
    "    if not os.path.exists(os.path.join(result_path,\"study0\"+str(i))):\n",
    "        os.makedirs(os.path.join(result_path,\"study0\"+str(i)))\n",
    "save_path = r\"C:\\Users\\DELL\\Desktop\\20credit\\EEG_eye_artifact\\results\\study05\"\n",
    "batch_size = 8\n",
    "epochs = 75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e951e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = []\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "for d in os.listdir(path):\n",
    "    for r2,d2,f2 in os.walk(os.path.join(path,d)):\n",
    "        for file in f2:\n",
    "            filepath=os.path.join(r2,file)\n",
    "            if file[-5] == '1':\n",
    "                c0.append(filepath)\n",
    "            if file[-5] == '2':\n",
    "                c1.append(filepath)\n",
    "            if file[-5] == '3':\n",
    "                c2.append(filepath)        \n",
    "            if file[-5] == '4':\n",
    "                c3.append(filepath)\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be78e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412 121 108 114\n"
     ]
    }
   ],
   "source": [
    "print(len(c0),len(c1),len(c2),len(c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63856d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound=max(max(len(c0),len(c1)),max(len(c2),len(c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_dups=random.sample(range(0, len(c1)), bound-len(c1))\n",
    "c2_dups=random.sample(range(0, len(c2)), bound-len(c2))\n",
    "c3_dups=random.sample(range(0, len(c3)), bound-len(c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e188ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c1_dups:\n",
    "    c1.append(c1[i])\n",
    "for i in c2_dups:\n",
    "    c2.append(c2[i])\n",
    "for i in c3_dups:\n",
    "    c3.append(c3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(c0),len(c1),len(c2),len(c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c718b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video=np.load(r\"C:\\Users\\DELL\\Desktop\\20credit\\EEG_eye_artifact\\video\\study01\\p01\\0_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb6f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bead7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def data_generator(files, batchsize):\n",
    "    while True:\n",
    "        cnt = 0\n",
    "        for i in range(len(files)):\n",
    "            image = np.load(files[i])\n",
    "            label = int(files[i][-5])-1\n",
    "\n",
    "            if i == 0 or cnt == 0:\n",
    "                xtrain = image\n",
    "                ytrain = np.array([label])\n",
    "            else:\n",
    "                xtrain = np.concatenate((xtrain, image), axis=0)\n",
    "                ytrain = np.concatenate((ytrain, np.array([label])), axis=0)\n",
    "            cnt += 1\n",
    "            if cnt == batchsize or i == (len(files)-1):\n",
    "                cnt = 0\n",
    "#                 print(xtrain.shape)\n",
    "                yield xtrain, ytrain\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9993ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, MaxPooling2D, Dropout, Flatten, Dense, LSTM, Concatenate\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Reshape, MaxPooling1D, Permute, Conv1D, BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Adagrad, SGD\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "class WeightClip(Constraint):\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "\n",
    "    def __call__(self, p):\n",
    "        return tf.keras.backend.clip(p, -self.c, self.c)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "                'c': self.c}\n",
    "\n",
    "\n",
    "\n",
    "def fpn():\n",
    "    input_layer = Input(shape=(112, 32, 32, 3))\n",
    "    c1 = TimeDistributed(Conv2D(name=\"C1\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1)), name='TC1')(input_layer)\n",
    "    c1 = TimeDistributed(BatchNormalization(name=\"B1\"), name='TB1')(c1)\n",
    "\n",
    "    c2 = TimeDistributed(Conv2D(name=\"C2\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1)), name='TC2')(c1)\n",
    "    c2 = TimeDistributed(BatchNormalization(name=\"B2\"), name='TB2')(c2)\n",
    "\n",
    "    c3 = TimeDistributed(Conv2D(name=\"C3\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1)), name='TC3')(c2)\n",
    "    c3 = TimeDistributed(BatchNormalization(name=\"B3\"), name='TB3')(c3)\n",
    "\n",
    "    c41 = TimeDistributed(Conv2D(name=\"C4\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=1), name='TC41')(c3)\n",
    "    c42 = TimeDistributed(Conv2D(name=\"C4\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=2), name='TC42')(c3)\n",
    "    c44 = TimeDistributed(Conv2D(name=\"C4\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=4), name='TC44')(c3)\n",
    "    c46 = TimeDistributed(Conv2D(name=\"C4\", filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=6), name='TC46')(c3)\n",
    "    c4_conc = Concatenate(name='aspp1')([c41, c42, c44, c46])\n",
    "    c4 = TimeDistributed((Conv2D(name='c4', filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1))), name='TC4')(c4_conc)\n",
    "\n",
    "    m1 = TimeDistributed(MaxPooling2D(name='M1', pool_size=(2, 2), strides=(2, 2)), name='TM1')(c4)\n",
    "    m1 = TimeDistributed(BatchNormalization(name='B4'), name='TB4')(m1)\n",
    "\n",
    "    c5 = TimeDistributed(Conv2D(name='C5', filters=64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1)), name='TC5')(m1)\n",
    "    c5 = TimeDistributed(BatchNormalization(name=\"B5\"), name='TB5')(c5)\n",
    "\n",
    "    c61 = TimeDistributed(Conv2D(name='C6', filters=64, kernel_size=3, activation='relu', padding='same', dilation_rate=1), name='TC61')(c5)\n",
    "    c62 = TimeDistributed(Conv2D(name='C6', filters=64, kernel_size=3, activation='relu', padding='same', dilation_rate=2), name='TC62')(c5)\n",
    "    c64 = TimeDistributed(Conv2D(name='C6', filters=64, kernel_size=3, activation='relu', padding='same', dilation_rate=4), name='TC64')(c5)\n",
    "    c66 = TimeDistributed(Conv2D(name='C6', filters=64, kernel_size=3, activation='relu', padding='same', dilation_rate=6), name='TC66')(c5)\n",
    "    c6_conc = Concatenate(name='aspp2')([c61, c62, c64, c66])\n",
    "    c6 = TimeDistributed((Conv2D(name='c4', filters=64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1))), name='TC6')(c6_conc)\n",
    "\n",
    "    m2 = TimeDistributed(MaxPooling2D(name='M2', pool_size=(2, 2), strides=(2, 2)), name='TM2')(c6)\n",
    "    m2 = TimeDistributed(BatchNormalization(name=\"B6\"), name='TB6')(m2)\n",
    "\n",
    "    c71 = TimeDistributed(Conv2D(name=\"C7\", filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=1), name='TC71')(m2)\n",
    "    c72 = TimeDistributed(Conv2D(name=\"C7\", filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=2), name='TC72')(m2)\n",
    "    c74 = TimeDistributed(Conv2D(name=\"C7\", filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=4), name='TC74')(m2)\n",
    "    c76 = TimeDistributed(Conv2D(name=\"C7\", filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1), dilation_rate=6), name='TC76')(m2)\n",
    "    c7_conc = Concatenate(name='aspp3')([c71, c72, c74, c76])\n",
    "    c7 = TimeDistributed(Conv2D(name='c7', filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.1)), name='Tc7')(c7_conc)\n",
    "\n",
    "\n",
    "\n",
    "    uc7 = TimeDistributed(UpSampling2D(name=\"UpSamp-C7\", size=(2, 2), interpolation='bilinear'), name='TD-UP-C7')(c7)\n",
    "    oc6 = TimeDistributed(Conv2D(name='1D-C6', filters=128, kernel_size=1, activation='relu', padding='same'), name='TD-1D-C6')(c6)\n",
    "    fpn1 = Concatenate(name=\"FPN1\")([uc7, oc6])\n",
    "    c100 = TimeDistributed(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'), name=\"FPN1_CNN\")(fpn1)\n",
    "    m100 = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), name=\"FPN1_MP\")(c100)\n",
    "    m100 = TimeDistributed(Flatten(), name=\"Flatten_FPN1_M100\")(m100)\n",
    "    lstm100 = LSTM(128, activation='tanh', kernel_constraint=WeightClip(100), name=\"LSTM100\")(m100)\n",
    "    conv1d100 = Conv1D(name=\"FPN1_CONV1D\", filters=64, kernel_size=3, strides=1, activation='relu', padding='valid')(m100)\n",
    "    conv1d100 = Flatten(name=\"Flatten_FPN1_C1D\")(conv1d100)\n",
    "    conc100 = Concatenate(name=\"CONC_FPN1\")([lstm100, conv1d100])\n",
    "    conc100 = Dropout(0.2)(conc100)\n",
    "    d100 = Dense(1024, activation='relu')(conc100)\n",
    "\n",
    "    ufpn1 = TimeDistributed(UpSampling2D(name=\"UpSamp-FPN1\", size=(2, 2), interpolation='bilinear'), name='TD-UP-FPN1')(fpn1)\n",
    "    oc4 = TimeDistributed(Conv2D(name='1D-C4', filters=256, kernel_size=1, activation='relu', padding='same'), name='TD-1D-C4')(c4)\n",
    "    fpn2 = Concatenate(name='FPN2')([ufpn1, oc4])\n",
    "    c200 = TimeDistributed(Conv2D(filters=512, kernel_size=3, activation='relu', padding='same'), name=\"FPN2_CNN\")(fpn2)\n",
    "    m200 = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), name=\"FPN2_MP\")(c200)\n",
    "    m200 = TimeDistributed(Flatten(), name=\"Flatten_FPN2_M200\")(m200)\n",
    "    lstm200 = LSTM(128, activation='tanh', kernel_constraint=WeightClip(100), name=\"LSTM200\")(m200)\n",
    "    conv1d200 = Conv1D(name=\"FPN2_CONV1D\", filters=64, kernel_size=3, strides=1, activation='relu', padding='valid')(m200)\n",
    "    conv1d200 = Flatten(name=\"Flatten_FPN2_C1D\")(conv1d200)\n",
    "    conc200 = Concatenate(name=\"CONC_FPN2\")([lstm200, conv1d200])\n",
    "    conc200 = Dropout(0.2)(conc200)\n",
    "    d200 = Dense(1024, activation='relu')(conc200)\n",
    "\n",
    "    m3 = TimeDistributed(MaxPooling2D(name='M3', pool_size=(2, 2), strides=(2, 2)), name='TM3')(c7)\n",
    "    m3 = TimeDistributed(BatchNormalization(name=\"B7\"), name='TB7')(m3)\n",
    "    m3 = TimeDistributed(Flatten(), name='TD-Flatten1')(m3)\n",
    "\n",
    "    #mp_conc = Concatenate(name=\"MP_CONC\")([m3, m100, m200])\n",
    "\n",
    "    lstm1 = LSTM(128, activation='tanh', kernel_regularizer=l2(0.1), kernel_constraint=WeightClip(100), name=\"L1\")(m3)\n",
    "    c8 = Conv1D(name=\"1DCONV\", filters=64, kernel_size=3, strides=1, kernel_regularizer=l2(0.1), activation='relu', padding='valid')(m3)\n",
    "    c8 = Flatten()(c8)\n",
    "    conc1 = Concatenate(name=\"CONC_LSTM_1D\")([lstm1, c8])\n",
    "    conc1 = Dropout(0.2)(conc1)\n",
    "    conc2 = Concatenate(name='conc')([conc1, d200, d100])\n",
    "    d1 = Dense(256, activation='relu')(conc2)\n",
    "    #d1 = Dense(256, activation='relu')(d1)\n",
    "    d1 = Dropout(0.2)(d1)\n",
    "    d1 = Dense(4, activation='softmax')(d1)\n",
    "    mod = Model(inputs=input_layer, outputs=d1)\n",
    "    adam = Adam(learning_rate=0.00001)\n",
    "    mod.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     print(\"yes\")\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c88e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = np.arange(1, bound+1, 1)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "test_acc = []\n",
    "i = 1\n",
    "for trainidx, testidx in kf.split(folds):\n",
    "#     print(trainidx, testidx)\n",
    "    train_lis = list(np.array(c0)[trainidx]) + list(np.array(c1)[trainidx]) + list(np.array(c2)[trainidx]) + list(np.array(c3)[trainidx])\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_lis)\n",
    "    random.shuffle(train_lis)\n",
    "    test_lis = list(np.array(c0)[testidx]) + list(np.array(c1)[testidx]) + list(np.array(c2)[testidx]) + list(np.array(c3)[testidx])\n",
    "    random.seed(1)\n",
    "    random.shuffle(test_lis)\n",
    "    random.shuffle(test_lis)\n",
    "\n",
    "    train_gen = data_generator(files=train_lis, batchsize=batch_size)\n",
    "#     print(train_gen)\n",
    "    print(\"[INFO] Training Model...\")\n",
    "    # strategy = tf.distribute.MirroredStrategy()\n",
    "    # with strategy.scope():\n",
    "    model = fpn()\n",
    "    history = model.fit(train_gen, verbose=1, epochs=epochs, steps_per_epoch=len(train_lis)//batch_size)\n",
    "\n",
    "    print(\"[INFO] Model trained. Getting predictions.\")\n",
    "    test_accuracy = training.get_predictions(model, test_lis, i, save_path, batch_size)\n",
    "    i += 1\n",
    "    test_acc.append(test_accuracy)\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Average test accuracy: \", np.sum(test_acc)/len(test_acc))\n",
    "print(test_acc)\n",
    "print(\"[DONE]...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bc9bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video= np.load(r\"C:\\Users\\DELL\\Desktop\\20credit\\EEG_eye_artifact\\video\\study02\\p11\\8_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ed5dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 112, 32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9bf53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(video, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95cb1ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 8.90400000e+04]\n",
      " [2.58905161e-02 1.00000000e+00]\n",
      " [2.97196160e-02 1.00000000e+00]\n",
      " ...\n",
      " [6.73204902e-01 1.00000000e+00]\n",
      " [6.73232756e-01 1.00000000e+00]\n",
      " [6.84977059e-01 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01c78279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255025"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
